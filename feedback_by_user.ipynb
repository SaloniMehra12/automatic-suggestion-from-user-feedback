{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hgDSNJAi_t_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "b36209f0-ff8d-40cd-dd17-0cb5cde5d1c4"
      },
      "source": [
        "#================================================models involved=======================================================\n",
        "import csv\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "import math\n",
        "import heapq\n",
        "from nltk.corpus import wordnet\n",
        "import numpy as np\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import gensim\n",
        "import nltk\n",
        "import nltk.data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_SEzE94jLFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===========================================================getting feedback from user====================================================\n",
        "feedback=\"I am feeling scared. someone is following me and is threatening me I am getting raped\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HMX6oaFjUA7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7efcec2e-e03d-419b-c9b9-9b9a9636a062"
      },
      "source": [
        "#==============================================================making model===================================================\n",
        "#------------------------------------------------------------initializing stop word------------------------------------\n",
        "stop_words = set(stopwords.words('english'))\n",
        "#------------------------------------------------------------getting list of final words-----------------------------------\n",
        "para=feedback\n",
        "word_tokens = word_tokenize(para)#break sentences into words and results in a list of words\n",
        "filtered_sentence = [w for w in word_tokens if not w in stop_words and w.isalpha()]\n",
        "print(filtered_sentence)\n",
        "#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++summarizing text++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "word_frequencies = {}\n",
        "for word in nltk.word_tokenize(para):\n",
        "    if word not in stop_words:\n",
        "        if word not in word_frequencies.keys():\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1\n",
        "maximum_frequncy = max(word_frequencies.values())\n",
        "\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
        "\n",
        "sentence_list=filtered_sentence\n",
        "sentence_scores = {}\n",
        "for sent in sentence_list:\n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_frequencies.keys():\n",
        "            if len(sent.split(' ')) < 30:\n",
        "                if sent not in sentence_scores.keys():\n",
        "                    sentence_scores[sent] = word_frequencies[word]\n",
        "                else:\n",
        "                    sentence_scores[sent] += word_frequencies[word]\n",
        "\n",
        "\n",
        "summary_sentences = heapq.nlargest(7, sentence_scores, key=sentence_scores.get)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'feeling', 'scared', 'someone', 'following', 'threatening', 'I', 'getting', 'raped']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RgZZBq0moDm",
        "colab_type": "code",
        "outputId": "2c2323b8-bba1-472a-af12-19209b70cca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#=======================================================list of crimes===========================================\n",
        "CRIMES={\"burglary\":list(word_synonyms(\"burglary\")),\"stalking\":list(word_synonyms(\"stalking\"))+(list(word_synonyms(\"following\"))),\"murder\":list(word_synonyms(\"murder\")),\"tease\":list(word_synonyms(\"tease\"))+list(word_synonyms(\"rape\")),\"threatening\":list(word_synonyms(\"threaten\"))}\n",
        "print(CRIMES)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'burglary': ['burglary'], 'stalking': ['haunt', 'stalk', 'stalking', 'still_hunt', 'abide_by', 'accompany', 'adopt', 'be', 'chase', 'come', 'come_after', 'comply', 'conform_to', 'espouse', 'fall_out', 'follow', 'followers', 'following', 'keep_abreast', 'keep_an_eye_on', 'keep_up', 'next', 'observe', 'play_along', 'postdate', 'pursual', 'pursue', 'pursuit', 'stick_to', 'stick_with', 'succeed', 'surveil', 'survey', 'take_after', 'trace', 'travel_along', 'undermentioned', 'watch', 'watch_over'], 'murder': ['bump_off', 'dispatch', 'execution', 'hit', 'mangle', 'murder', 'mutilate', 'off', 'polish_off', 'remove', 'slay', 'slaying'], 'tease': ['annoyer', 'badger', 'bait', 'beleaguer', 'bug', 'card', 'cod', 'coquette', 'flirt', 'fluff', 'loosen', 'minx', 'pester', 'prickteaser', 'rag', 'rally', 'razz', 'ribbing', 'ride', 'tantalise', 'tantalization', 'tantalize', 'taunt', 'tease', 'tease_apart', 'teaser', 'teasing', 'twit', 'vamp', 'vamper', 'vexer', 'Brassica_napus', 'assault', 'colza', 'despoil', 'dishonor', 'dishonour', 'outrage', 'plunder', 'rape', 'rapine', 'ravish', 'ravishment', 'spoil', 'violate', 'violation'], 'threatening': ['endanger', 'imperil', 'jeopardise', 'jeopardize', 'menace', 'peril', 'threaten']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2CeQnDSjqse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fec80cae-0e04-4c9c-bb73-98924b50cf72"
      },
      "source": [
        "#==========================================================mapping with crime category=============================================\n",
        "#-----------------------------------------------------------map_function--------------------------------------------------------\n",
        "def keys(val):\n",
        "  for k,v in CRIMES.items():\n",
        "    if val in k:\n",
        "      return k\n",
        "    elif val in v:\n",
        "      return k\n",
        "    else:\n",
        "      continue\n",
        "  return None\n",
        "#------------------------------------------------------word_synonyms function for accuracy------------------------------------------\n",
        "def word_synonyms(word):\n",
        "    synonyms = []#list of synonyms of word\n",
        "    for syn in wordnet.synsets(word):#for each synonym in set of synonyms\n",
        "        for l in syn.lemmas():#for each meaningful synonym\n",
        "            synonyms.append(l.name())#get that meaningful and siliar synonym\n",
        "    x = np.array(synonyms)\n",
        "    return (np.unique(x))#making unique list of synonyms\n",
        "#------------------------------------------------------getting output category--------------------------------------------------------\n",
        "output=[]\n",
        "for word in summary_sentences:\n",
        "  word_syn=word_synonyms(word)\n",
        "  for w in word_syn:\n",
        "    if(keys(w)!=None):\n",
        "      a=keys(w)\n",
        "      output.append(a)\n",
        "      break;\n",
        "    else:\n",
        "      continue\n",
        "print(list(np.unique(np.array(output))))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['stalking', 'tease', 'threatening']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZE15195lC3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}